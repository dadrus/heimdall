logging {
  level = "debug"
  format = "json" // "logfmt"

  write_to = [loki.write.default.receiver]
}

//////////////////////////////////////////////////
//   Pod Discovery & Shared Labels
//////////////////////////////////////////////////

discovery.kubernetes "pod" {
  role = "pod"
}

discovery.relabel "common" {
  targets = discovery.kubernetes.pod.targets

  // Core label set for pod-based targets
  rule {
    target_label = "cluster"
    action       = "replace"
    replacement  = "${cluster_name}"
  }

  rule {
    source_labels = ["__meta_kubernetes_pod_node_name"]
    target_label  = "node"
    action        = "replace"
  }

  rule {
    source_labels = ["__meta_kubernetes_namespace"]
    target_label  = "namespace"
    action        = "replace"
  }

  rule {
    source_labels = ["__meta_kubernetes_pod_name"]
    target_label  = "pod"
    action        = "replace"
  }

  rule {
    source_labels = ["__meta_kubernetes_pod_container_name"]
    target_label  = "container"
    action        = "replace"
  }

  rule {
    source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
    target_label  = "app"
    action        = "replace"
  }

  // fallback 1: pod label "app"
  rule {
    source_labels = ["app", "__meta_kubernetes_pod_label_app"]
    target_label  = "app"
    action        = "replace"
    regex         = "^$;(.*)$"
    replacement   = "$1"
  }

  // fallback 2: pod label "k8s-app"
  rule {
    source_labels = ["app", "__meta_kubernetes_pod_label_k8s_app"]
    target_label  = "app"
    action        = "replace"
    regex         = "^$;(.*)$"
    replacement   = "$1"
  }

  rule {
    source_labels = ["namespace", "app"]
    separator     = "/"
    target_label  = "job"
    action        = "replace"
  }
}

//////////////////////////////////////////////////
//             Telemetry Sinks
//////////////////////////////////////////////////

// write logs to Loki
loki.write "default" {
  endpoint {
    url = "${loki_endpoint}/loki/api/v1/push"
  }
}

// write metrics to Prometheus
prometheus.remote_write "default" {
  endpoint {
    url = "${prometheus_endpoint}/api/v1/write"
  }
}

// write traces to Tempo
otelcol.exporter.otlp "default" {
  client {
    endpoint = "${otel_traces_endpoint}"
    tls {
      insecure             = true
      insecure_skip_verify = true
    }
  }
}

// write profiles to Pyroscope
pyroscope.write "default" {
  endpoint {
    url = "${pyroscope_endpoint}"
  }
}

//////////////////////////////////////////////////
//             Log Sources
//////////////////////////////////////////////////

// *********************************
//          System Logs
// *********************************

local.file_match "node_logs" {
  path_targets = [{
      __path__  = "/var/log/syslog",
      job       = "node/syslog",
      node      = sys.env("HOSTNAME"),
      cluster   = "${cluster_name}",
  }]
}

loki.source.file "node_logs" {
  targets    = local.file_match.node_logs.targets
  forward_to = [loki.process.node_logs.receiver]
}

loki.process "node_logs" {
  stage.template {
    source   = "raw"
    template = "{{ . }}"
  }

  // optional <PRI>, then "Dec 18 13:10:28 host app[pid]: msg"
  stage.regex {
    expression = "^(?:<(?P<pri>\\d+)>)?(?P<ts>[A-Z][a-z]{2}\\s+\\d{1,2}\\s+\\d{2}:\\d{2}:\\d{2})\\s+(?P<host>\\S+)\\s+(?P<app>[^\\[:]+)(?:\\[(?P<pid>\\d+)\\])?:\\s+(?P<msg>.*)$"
  }

  stage.match {
    selector = "{ts!=\"\"}"

    stage.timestamp {
      source   = "ts"
      format   = "Jan _2 15:04:05"
    }

    stage.template {
      source = "out"
      template = `
          {{- $pri := toString .pri -}}
          {{- $lvl := "info" -}}
          {{- if ne $pri "" -}}
            {{- $sev := mod (int $pri) 8 -}}
            {{- if eq $sev 7 -}}{{- $lvl = "debug" -}}{{- end -}}
            {{- if eq $sev 6 -}}{{- $lvl = "info"  -}}{{- end -}}
            {{- if eq $sev 5 -}}{{- $lvl = "notice" -}}{{- end -}}
            {{- if eq $sev 4 -}}{{- $lvl = "warn"  -}}{{- end -}}
            {{- if eq $sev 3 -}}{{- $lvl = "error" -}}{{- end -}}
            {{- if eq $sev 2 -}}{{- $lvl = "critical" -}}{{- end -}}
            {{- if eq $sev 1 -}}{{- $lvl = "alert" -}}{{- end -}}
            {{- if eq $sev 0 -}}{{- $lvl = "emerg" -}}{{- end -}}
          {{- end -}}
          {{- toJson (dict "level" $lvl "app" (toString .app) "pid" (toString .pid) "message" (toString .msg)) -}}`
    }

    stage.output { source = "out" }
  }

  stage.match {
    selector = "{ts=\"\"}"

    stage.template {
      source   = "out"
      template = `{{- toJson (dict "level" "info" "message" (toString .raw)) -}}`
    }

    stage.output { source = "out" }
  }

  forward_to = [loki.write.default.receiver]
}

// *********************************
//            Pods Logs
// *********************************

loki.source.kubernetes "pod_logs" {
  targets    = discovery.relabel.common.output
  forward_to = [loki.process.pod_logs.receiver]
}

loki.process "pod_logs" {
  stage.pack {
    labels = ["pod", "container"]
  }

  stage.json {
    expressions = {
      entry = "_entry",
    }
  }

  stage.output { source="entry" }

/**
  stage.template {
    source   = "entry"
    template = "{{ .Entry }}"
  }

  stage.replace {
    source     = "entry"
    expression = "[[:space:]]+$"
    replace    = ""
  }

  stage.template {
    source   = "fmt_detect"
    template = `{{- if regexMatch "^[[:space:]]*{" .entry -}}json{{- else if regexMatch "^[IWEF][0-9]{4}[[:space:]]" .entry -}}klog{{- else if regexMatch "(^|[[:space:]])[A-Za-z_][A-Za-z0-9_.-]*=" .entry -}}logfmt{{- else -}}raw{{- end -}}`
  }

  stage.labels { values = { log_format = "fmt_detect" } }

  stage.match {
    selector = "{log_format=\"json\"}"

    stage.json {
      source = "entry"
      expressions = {
        gelf_version = "version",
        gelf_ts      = "timestamp",
        gelf_level   = "level",
        gelf_sm      = "short_message",
      }
    }

    stage.template {
      source = "fmt"
      template = `{{- if and
          (eq .gelf_version "1.1")
          (ne .gelf_ts "")
          (regexMatch "^[0-7]$" (toString .gelf_level))
          (ne .gelf_sm "")
        -}}gelf{{- else -}}json{{- end -}}`
    }

    stage.labels { values = { log_format = "fmt" } }
  }

  stage.match {
    selector = "{log_format=\"gelf\"}"

    stage.json {
      source = "entry"
      expressions = { gelf_ts = "timestamp" }
    }

    stage.timestamp {
      source="gelf_ts"
      format="Unix"
    }

    stage.template {
      source = "entry"
      template = `
         {{- $m := fromJson .entry -}}
         {{- range $k, $v := $m -}}
           {{- if hasPrefix $k "_" -}}
             {{- $_ := set $m (trimPrefix "_" $k) $v -}}
             {{- $_ := unset $m $k -}}
           {{- end -}}
         {{- end -}}
         {{- $_ := set $m "level" (lower (get $m "level_name")) -}}
         {{- $_ := unset $m "level_name" -}}
         {{- $_ := set $m "message" (get $m "short_message") -}}
         {{- $_ := unset $m "short_message" -}}
         {{- $_ := unset $m "timestamp" -}}
         {{- $_ := unset $m "version" -}}
         {{- $_ := unset $m "host" -}}
         {{- toJson $m -}}`
    }
  }

  stage.match {
    selector = "{log_format=\"logfmt\"}"

    stage.replace {
      source="entry"
      expression="\\\\\""
      replace="\""
    }

    stage.logfmt {
      source = "entry"
      mapping = {
        level = "level",
        msg   = "msg",
        ts    = "ts",
      }
    }

    stage.match {
      selector = "{ts!=\"\"}"

      stage.timestamp {
        source="ts"
        format="RFC3339Nano"
      }
    }

    stage.template {
      source = "entry"
      template = `
          {{- $m := . -}}
          {{- $_ := set $m "level" (lower (get $m "level")) -}}
          {{- $_ := set $m "message" (get $m "msg") -}}
          {{- $_ := unset $m "msg" -}}
          {{- $_ := unset $m "ts" -}}
          {{- toJson $m -}}`
    }
  }

  stage.match {
    selector = "{log_format=\"klog\"}"

    stage.regex {
      source = "entry"
      expression = "^(?P<sev>[IWEF])\\d{4}\\s+\\d{2}:\\d{2}:\\d{2}\\.\\d+\\s+(?P<pid>\\d+)\\s+(?P<file>[^:]+):(?P<line>\\d+)]\\s+(?P<msg>.*)$"
    }

    stage.template {
      source = "entry"
      template = `
          {{- $lvl := "info" -}}
          {{- if eq .sev "W" -}}{{- $lvl = "warn" -}}{{- end -}}
          {{- if eq .sev "E" -}}{{- $lvl = "error" -}}{{- end -}}
          {{- if eq .sev "F" -}}{{- $lvl = "fatal" -}}{{- end -}}
          {{- toJson (dict "level" $lvl "message" .msg "caller" (printf "%s:%s" .file .line) "pid" .pid) -}}`
    }
  }

  stage.match {
    selector = "{log_format=\"json\"}"

    stage.json {
      source = "entry"
      expressions = { ts = "ts", time = "time" }
    }

    stage.match {
      selector = "{ts!=\"\"}"

      stage.timestamp {
        source="ts"
        format="RFC3339Nano"
      }
    }

    stage.match {
      selector = "{ts=\"\",time!=\"\"}"

      stage.timestamp {
        source="time"
        format="RFC3339Nano"
      }
    }

    stage.template {
      source = "entry"
      template = `
         {{- $m := fromJson .entry -}}
         {{- $_ := set $m "level" (lower (get $m "level")) -}}

         {{- if hasKey $m "msg" -}}
           {{- $_ := set $m "message" (get $m "msg") -}}
           {{- $_ := unset $m "msg" -}}
         {{- end -}}

         {{- if hasKey $m "traceID" -}}
           {{- $_ := set $m "trace_id" (get $m "traceID") -}}
           {{- $_ := unset $m "traceID" -}}
         {{- end -}}
         {{- if hasKey $m "traceId" -}}
           {{- $_ := set $m "trace_id" (get $m "traceId") -}}
           {{- $_ := unset $m "traceId" -}}
         {{- end -}}
         {{- if hasKey $m "spanID" -}}
           {{- $_ := set $m "span_id" (get $m "spanID") -}}
           {{- $_ := unset $m "spanID" -}}
         {{- end -}}
         {{- if hasKey $m "spanId" -}}
           {{- $_ := set $m "span_id" (get $m "spanId") -}}
           {{- $_ := unset $m "spanId" -}}
         {{- end -}}

         {{- $_ := unset $m "ts" -}}
         {{- $_ := unset $m "time" -}}
         {{- $_ := unset $m "timestamp" -}}

         {{- toJson $m -}}`
    }
  }

  stage.match {
    selector = "{log_format=\"raw\"}"

    stage.template {
      source   = "entry"
      template = `{{- toJson (dict "level" "info" "message" .entry) -}}`
    }
  }

  stage.output { source="entry" }

  stage.label_drop { values=["log_format"] }

**/
  forward_to = [loki.write.default.receiver]
}

// *********************************
//         Cluster Event Logs
// *********************************

loki.source.kubernetes_events "cluster_events" {
  job_name   = "integrations/kubernetes/eventhandler"
  log_format = "logfmt"
  forward_to = [loki.process.cluster_events.receiver]
}

loki.process "cluster_events" {
  stage.static_labels {
    values = {
      cluster = "${cluster_name}",
      job     = "kubernetes/events",
    }
  }

  stage.logfmt {
    mapping = {
      type = "type",
      msg  = "msg",
    }
  }

  stage.template {
    source = "output"
    template = `
        {{- $m := . -}}
        {{- $lvl := "info" -}}
        {{- if eq (get $m "type") "Warning" -}}
          {{- $lvl = "warn" -}}
        {{- end -}}
        {{- $_ := set $m "level" $lvl -}}

        {{- if hasKey $m "msg" -}}
          {{- $_ := set $m "message" (get $m "msg") -}}
          {{- $_ := unset $m "msg" -}}
        {{- end -}}

        {{- toJson $m -}}`
  }

  stage.output { source = "output" }

  forward_to = [loki.write.default.receiver]
}


//////////////////////////////////////////////////
//         Metrics Sources
//////////////////////////////////////////////////


// *********************************
//    collect and exposes metrics about Alloy itself
// *********************************

prometheus.exporter.self "default" {}

prometheus.scrape "alloy" {
  targets    = prometheus.exporter.self.default.targets
  forward_to = [prometheus.relabel.normalize.receiver]
}

// *********************************
//    hw & OS metrics
// *********************************

prometheus.exporter.unix "default" {
  include_exporter_metrics = true
}

prometheus.scrape "unix" {
  targets    = prometheus.exporter.unix.default.targets
  forward_to = [prometheus.relabel.normalize.receiver]
}

// *********************************
//    Scrape targets referenced by prometheus operator CRs
// *********************************

prometheus.operator.podmonitors "default" {
  forward_to = [prometheus.relabel.normalize.receiver]
}

prometheus.operator.servicemonitors "default" {
  forward_to = [prometheus.relabel.normalize.receiver]
}

prometheus.operator.probes "default" {
  forward_to = [prometheus.relabel.normalize.receiver]
}

// *********************************
// Normalization of metrics labels
// *********************************

prometheus.relabel "normalize" {
  rule {
    target_label = "cluster"
    action       = "replace"
    replacement  = "${cluster_name}"
  }

  rule {
    source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
    target_label  = "app"
    action        = "replace"
  }

  rule {
    source_labels = ["app", "__meta_kubernetes_pod_label_app"]
    target_label  = "app"
    action        = "replace"
    regex         = "^$;(.*)$"
    replacement   = "$1"
  }

  rule {
    source_labels = ["app", "__meta_kubernetes_pod_label_k8s_app"]
    target_label  = "app"
    action        = "replace"
    regex         = "^$;(.*)$"
    replacement   = "$1"
  }

  rule {
    source_labels = ["app", "__meta_kubernetes_pod_label_kubernetes_io_name"]
    target_label  = "app"
    action        = "replace"
    regex         = "^$;(.*)$"
    replacement   = "$1"
  }

  forward_to = [prometheus.remote_write.default.receiver]
}


//////////////////////////////////////////////////
//         OpenTelemetry Data Delivery
//////////////////////////////////////////////////

otelcol.receiver.otlp "default" {
  grpc {}
  http {}

  output {
    metrics = [otelcol.processor.k8sattributes.default.input]
    logs    = [otelcol.processor.k8sattributes.default.input]
    traces  = [otelcol.processor.k8sattributes.default.input]
  }
}

// Enrich incoming OTLP data with Kubernetes metadata
otelcol.processor.k8sattributes "default" {
  wait_for_metadata = true

  extract {
    metadata = [
      "k8s.namespace.name",
      "k8s.pod.name",
      "k8s.pod.start_time",
      "k8s.container.name",
      "k8s.node.name",
      "k8s.deployment.name",
      "k8s.statefulset.name",
      "k8s.daemonset.name",
      "k8s.cronjob.name",
      "k8s.job.name",
    ]
  }

  output {
    metrics = [otelcol.processor.transform.metrics.input]
    logs    = [otelcol.processor.transform.logs.input]
    traces  = [otelcol.processor.transform.traces.input]
  }
}

otelcol.processor.transform "metrics" {
  error_mode = "ignore"

  metric_statements {
    context = "datapoint"
    statements = [
      `set(attributes["app"], resource.attributes["service.name"])`,
      `set(attributes["namespace"],    resource.attributes["k8s.namespace.name"])`,
      `set(attributes["pod"],          resource.attributes["k8s.pod.name"])`,
      `set(attributes["container"],    resource.attributes["k8s.container.name"])`,
      `set(attributes["node"],         resource.attributes["k8s.node.name"])`,
      `set(attributes["cluster"],      "${cluster_name}")`,
    ]
  }

  output { metrics = [otelcol.exporter.prometheus.default.input] }
}

otelcol.processor.transform "logs" {
  error_mode = "ignore"

  log_statements {
    context = "resource"
    statements = [
      `set(attributes["app"], attributes["service.name"])`,
      `set(attributes["namespace"],    attributes["k8s.namespace.name"])`,
      `set(attributes["pod"],          attributes["k8s.pod.name"])`,
      `set(attributes["container"],    attributes["k8s.container.name"])`,
      `set(attributes["node"],         attributes["k8s.node.name"])`,
      `set(attributes["cluster"],      "${cluster_name}")`,
    ]
  }

  output { logs = [otelcol.processor.attributes.loki_labels.input] }
}

otelcol.processor.transform "traces" {
  error_mode = "ignore"

  trace_statements {
    context = "resource"
    statements = [
      `set(attributes["app"], attributes["service.name"])`,
      `set(attributes["namespace"],    attributes["k8s.namespace.name"])`,
      `set(attributes["pod"],          attributes["k8s.pod.name"])`,
      `set(attributes["container"],    attributes["k8s.container.name"])`,
      `set(attributes["node"],         attributes["k8s.node.name"])`,
      `set(attributes["cluster"],      "${cluster_name}")`,
    ]
  }

  output { traces = [otelcol.exporter.otlp.default.input] }
}

// Promote only stable canonical keys to Loki labels (lower cardinality).
otelcol.processor.attributes "loki_labels" {
  action {
    key    = "loki.resource.labels"
    action = "insert"
    value  = "cluster,namespace,app,node"
  }

  output { logs = [otelcol.exporter.loki.default.input] }
}

otelcol.exporter.loki "default" {
  forward_to = [loki.write.default.receiver]
}

// exports OTEL metrics to Prometheus
otelcol.exporter.prometheus "default" {
  forward_to = [prometheus.relabel.normalize.receiver]
}

//////////////////////////////////////////////////
//         Profiling Sources
//////////////////////////////////////////////////

discovery.relabel "pod_profiling" {
  targets = discovery.relabel.common.output

  // filter only pods with annotation phlare.grafana.com/scrape="true"
  rule {
    source_labels = ["__meta_kubernetes_pod_annotation_phlare_grafana_com_scrape"]
    action        = "keep"
    regex         = "true"
  }

  // __address__ = <pod_ip>:<port from annotation>
  rule {
    source_labels = [
      "__meta_kubernetes_pod_ip",
      "__meta_kubernetes_pod_annotation_phlare_grafana_com_port",
    ]
    separator    = ":"
    target_label = "__address__"
    action       = "replace"
  }
}

pyroscope.scrape "pod_profiles" {
  targets    = discovery.relabel.pod_profiling.output
  forward_to = [pyroscope.write.default.receiver]
}